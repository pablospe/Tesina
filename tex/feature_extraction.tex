\section{Feature extraction}
\label{feature_extraction}

Las técnicas usuales para \textit{handwriting recognition} tratan de encontrar \textit{features} particulares sobre un conjunto de símbolos, citemos por ejemplo los dígitos. Pero al cambiar dicho conjunto, estos features dejan de ser efectivos, no discriminan correctamente. Se vuelve impráctico desarrollar heurísticas para reconocer features específicos para cada símbolo.
% Sobre todo si se tiene en cuenta que símbolos matemáticos pueden ser inventados o agregados en la marcha.
Por lo que es deseable buscar una representación que permita ser aplicada sin importar qué tipo de símbolo se trate; ya sea un dígito, una letra o un símbolo matemático.

Unos de los mayores problemas con los métodos de reconocimientos tradicionales es que los trazos son tratados como secuencias de puntos (en \textit{discreto}), en vez de verlos como lo que realmente son, curvas (en \textit{continuo}).
% son pensados como una secuencia de puntos. El problema con ésto es que no se lo están tratando como lo que realmente son, curvas.

\subsection{Trazos discretos como curvas continuas}
\label{Trazos_como_curvas_continuas}

En vez de describir a los trazos como una secuencia de puntos, éstos pueden ser representados por aproximaciones de curvas, figura~\ref{fig:trazos_vs_curvas}. Se mostrará que se necesitan menos de vein\-tes~($20$) coeficientes de una serie para representar un trazo.
% \vspace*{-0.1cm}
    \begin{figure}[!htbp]
    \centering
    \includegraphics[scale=0.4]{imagen/trazos_como_curva.pdf}
%     \includegraphics[scale=0.23]{imagen/x_e_y_en_t.pdf}
    \caption{Trazos como curvas paramétricas: $r(t) = \{x(t),y(t)\}$ }
    \label{fig:trazos_vs_curvas}
    \end{figure}

\vspace*{-0.2cm}
\noindent
Observar que se necesitan aproximar dos curvas: $x(t)$, $y(t)$ por símbolos, figura~\ref{fig:x_e_y_en_t}.
% \vspace*{-0.15cm}
    \begin{figure}[!htbp]
    \centering
    \includegraphics[scale=0.29]{imagen/x_e_y_en_t.pdf}
    \caption{En \textcolor{red}{rojo} las aproximaciones de $x(t)$, $y(t)$}
    \label{fig:x_e_y_en_t}
    \end{figure}

\vspace*{-0.2cm}
\noindent
Trabajos anteriores \cite{Succinct} han demostrado cómo las coordenadas $x(t)$, $y(t)$ de símbolos escritos a mano pueden ser representados como expansión en series de polinomios ortogonales de \textit{Chebyshev}; y que los coeficientes de las series truncadas además de ser las aproximaciones buscadas, pueden ser usados para clasificación y reconocimiento.

De manera similar, en este trabajo se utiliza un número finito de \textit{\textbf{momentos matemáticos}} para la reconstrucción de funciones (las curvas) como series truncadas de polinomios ortogonales de \textit{\textbf{Legendre}}, siguiendo las ideas presentadas en los artículos \cite{Moments} y \cite{OnlineModeling}. Este problema es conocido como \textit{\textbf{Hausdorff Moment Problem}} \cite{HausdorffMomentProblem}. Una alternativa a este método para la obtención de las aproximaciones a las curvas (es decir, los coeficientes de las series truncadas) es utilizar \textit{aproximación por \textbf{mínimos cuadrados}} a través de la \textit{\textbf{pseudo-inversa} de Moore-Penrose}, permitiendo este enfoque utilizar polinomios ortogonales arbitrarios, en particular polinomios de \textit{\textbf{Legendre}}, \textit{\textbf{Legendre-Sobolev}} y \textit{\textbf{Chebyshev}}.

% usar diferentes tipos de polinomios ortogonales, en particular \textit{\textbf{Legendre}}, \textit{\textbf{Legendre-Sobolev}} y \textit{\textbf{Chebyshev}}.


% En lo siguiente se irán introduciendo algunos conceptos para finalmente llegar a la explicación de qué son los features, y cómo obtenerlos.


\subsection{Representación con series}
Se desea entonces aproximar las funciones $x(t), y(t)$ de los trazos. Como se indicó en la sección~\ref{Series_de_funciones_ortogonales}, ésto puede hacerse como expansión de series de polinomios ortogonales; según la ecuación~(\ref{eq:alpha_inner_prod}),
\[
\left\{
\begin{array}{rcl}
% \begin{equation}
% \begin{split}
x(t) & \approx & \sum_{i=0}^{d}{\alpha}_{i}\,{B}_{i}(t) \\
y(t) & \approx & \sum_{i=0}^{d}{\beta}_{i}\,{B}_{i}(t)
% \end{split}
% \end{equation}
\end{array}
\right.
\]

% \noindent
Clasificación puede ser obtenida, por ejemplo, al medir la distancia Euclidiana de los vectores $({\alpha}_{0}, \dots ,{\alpha}_{d}, {\beta}_{0}, \dots ,{\beta}_{d})$ entre los distintos trazos.

Consideraremos \textbf{features} a estos vectores que tienen dimensión $2\:(d+1)$. En lo siguiente, se mostrará dos formas de calcularlos y, en secciones posteriores, resultados que avalen que los features son lo suficientemente representativos como para clasificar de manera precisa a los trazos.

% Se mostrará dos formas de calcularlos, una por medio de momentos matemáticos (sección \ref{HausdorffMomentProblem}) y otra a través aproximación por mínimo cuadrados usando la pseudo-inversa (sección \ref{leastSquare}), y resultados que avalen que los features son lo suficientemente representativos como para clasificar de manera precisa los trazos.




\subsection{Momentos}
\label{Momentos}

\subsubsection{Definición}
Los momentos matemáticos de una función $f$ definida en $[0,1]$ son
\begin{align}
\label{eq:momentos}
\mu_{k} & \doteq \int_{0}^{1}{f(\lambda)\,\lambda^k\,d\lambda}
\end{align}

% \ell


\subsubsection{Hausdorff Moment Problem}
\label{HausdorffMomentProblem}
Este problema consiste en recuperar a partir de una secuencia finita de  momentos $\{\mu_k\}_{k=0,1,2,...}$ una función $f$ en el dominio $[0,1]$.
% Ver \cite{Moments} para un desarrollo más teórico del problema.
% Aquí se presenta una explicación simplificada.

Con el fin de facilitar el desarrollo, recordaremos algunas definiciones y ecuaciones previas.
%de la reconstrucción de funciones mediante momentos.
Se supondrá que el dominio es $[0,1]$, y que la función peso es $w(t)=1$ para poder trabajar con los polinomios de \textit{Legendre}. Por lo que el producto interno en \refEQ{def:inner_product} queda
\begin{align}
\label{eq:inner_product_2}
 \langle f, g \rangle & = \int_{0}^{1}f(t)\,g(t)\,dt
\end{align}
Escribamos nuevamente la ecuación \refEQ{eq:legendre}
\begin{align}
\label{eq:legendre2}
L_i(t) &= \sum_{j=0}^{i}{ C_{ij}\,x^j }
\end{align}
y también la ecuación \refEQ{eq:aprox}, pero ésta reemplazando ${B}_{i}$ por ${L}_{i}$
\begin{align*}
f(t) & \approx \sum_{i=0}^{d}{\alpha}_{i}\,{L}_{i}(t)
\end{align*}
Ahora, a partir de \vspace*{-0.4cm}
% \refEQ{eq:alpha_inner_prod}
% \begin{align*}
% {\alpha}_{i} & = \langle f, L_i \rangle
% \end{align*}
% & =  \quad \langle \rangle  \\
% & =  \quad \langle \rangle  \\
% & =  \quad \langle \rangle  \\
% & =  \quad \langle \rangle  \\
\begin{align*}
\hspace*{4cm}  & {\alpha}_{i}  \\
 = \quad &   \quad \langle \text{~ por}~\refEQ{eq:alpha_inner_prod} ~ \rangle  \\
   &   \langle f, L_i \rangle \\
 = \quad &   \quad \langle \text{~ expansión del producto interno}~\refEQ{eq:inner_product_2} ~ \rangle  \\
   &   \int_{0}^{1}f(t)\,L_i(t)\,dt \\
 = \quad &   \quad \langle \text{~ definición de $L_i(t)$, ecuación}~\refEQ{eq:legendre} ~ \rangle  \\
   &   \int_{0}^{1}f(t)\, \left( \sum_{j=0}^{i}{ C_{ij}\,x^j } \right) \,dt \\
 = \quad &   \quad \langle \text{~ reordenación de términos, sumatoria afuera} ~ \rangle  \\
   &   \sum_{j=0}^{i}{ C_{ij}\,\underbrace{\left( \int_{0}^{1}f(t)\,x^j\,dt \right)}_{\mu_j} } \\
 = \quad &   \quad \langle \text{~ definición de momento}~\refEQ{eq:momentos} ~ \rangle  \\
   &   \sum_{j=0}^{i}{ C_{ij}\,\mu_j} \\
 = \quad &   \quad \langle \text{~ escrito matricialmente}~ \rangle  \\
   &   \mathbf{C\,\mu}
\end{align*}



\subsubsection{Cálculos numéricos de los momentos}


\subsection{Aproximación por mínimos cuadrados}
\label{leastSquare}

