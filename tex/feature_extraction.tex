\section{Feature extraction}
\label{feature_extraction}

Las técnicas usuales para \textit{handwriting recognition} tratan de encontrar \textit{features} particulares sobre un conjunto de símbolos, citemos por ejemplo los dígitos. Pero al cambiar dicho conjunto, estos features dejan de ser efectivos, no discriminan correctamente. Se vuelve impráctico desarrollar heurísticas para reconocer features específicos para cada símbolo.
% Sobre todo si se tiene en cuenta que símbolos matemáticos pueden ser inventados o agregados en la marcha.
Por lo que es deseable buscar una representación que permita ser aplicada sin importar qué tipo de símbolo se trate; ya sea un dígito, una letra o un símbolo matemático.

Unos de los mayores problemas con los métodos de reconocimientos tradicionales es que los trazos son tratados como secuencias de puntos (en \textit{discreto}), en vez de verlos como lo que realmente son, curvas (en \textit{continuo}).
% son pensados como una secuencia de puntos. El problema con ésto es que no se lo están tratando como lo que realmente son, curvas.

\subsection{Trazos discretos como curvas continuas}
\label{Trazos_como_curvas_continuas}

En vez de describir a los trazos como una secuencia de puntos, éstos pueden ser representados por aproximaciones de curvas, figura~\ref{fig:trazos_vs_curvas}. Se mostrará que se necesitan menos de vein\-tes~($20$) coeficientes de una serie para representar un trazo.
% \vspace*{-0.1cm}
    \begin{figure}[!htbp]
    \centering
    \includegraphics[scale=0.4]{imagen/trazos_como_curva.pdf}
%     \includegraphics[scale=0.23]{imagen/x_e_y_en_t.pdf}
    \caption{Trazos como curvas paramétricas: $r(t) = \{x(t),y(t)\}$ }
    \label{fig:trazos_vs_curvas}
    \end{figure}

\vspace*{-0.2cm}
\noindent
Observar que se necesitan aproximar dos curvas: $x(t)$, $y(t)$ por símbolos, figura~\ref{fig:x_e_y_en_t}.
% \vspace*{-0.15cm}
    \begin{figure}[!htbp]
    \centering
    \includegraphics[scale=0.29]{imagen/x_e_y_en_t.pdf}
    \caption{En \textcolor{red}{rojo} las aproximaciones de $x(t)$, $y(t)$}
    \label{fig:x_e_y_en_t}
    \end{figure}

\vspace*{-0.2cm}
\noindent
Trabajos anteriores \cite{Succinct} han demostrado cómo las coordenadas $x(t)$, $y(t)$ de símbolos escritos a mano pueden ser representados como expansión en series de polinomios ortogonales de \textit{Chebyshev}; y que los coeficientes de las series truncadas además de ser las aproximaciones buscadas, pueden ser usados para clasificación y reconocimiento.

De manera similar, en este trabajo se utiliza un número finito de \textit{\textbf{momentos matemáticos}} para la reconstrucción de funciones (las curvas) como series truncadas de polinomios ortogonales de \textit{\textbf{Legendre}}, siguiendo las ideas presentadas en los artículos \cite{Moments} y \cite{OnlineModeling}. Este problema es conocido como \textit{\textbf{Hausdorff Moment Problem}} \cite{HausdorffMomentProblem}. Una alternativa a este método para la obtención de las aproximaciones a las curvas (es decir, los coeficientes de las series truncadas) es utilizar \textit{aproximación por \textbf{mínimos cuadrados}} a través de la \textit{\textbf{pseudo-inversa} de Moore-Penrose}, permitiendo este enfoque utilizar polinomios ortogonales arbitrarios, en particular polinomios de \textit{\textbf{Legendre}}, \textit{\textbf{Legendre-Sobolev}} y \textit{\textbf{Chebyshev}}.

% usar diferentes tipos de polinomios ortogonales, en particular \textit{\textbf{Legendre}}, \textit{\textbf{Legendre-Sobolev}} y \textit{\textbf{Chebyshev}}.


% En lo siguiente se irán introduciendo algunos conceptos para finalmente llegar a la explicación de qué son los features, y cómo obtenerlos.


\subsection{Representación con series}
Se desea entonces aproximar las funciones $x(t), y(t)$ de los trazos. Como se indicó en la sección~\ref{Series_de_funciones_ortogonales}, ésto puede hacerse como expansión de series de polinomios ortogonales; según la ecuación~(\ref{eq:alpha_inner_prod}),
\[
\left\{
\begin{array}{rcl}
% \begin{equation}
% \begin{split}
x(t) & \approx & \sum_{i=0}^{d}{\alpha}_{i}\,{B}_{i}(t) \\
y(t) & \approx & \sum_{i=0}^{d}{\beta}_{i}\,{B}_{i}(t)
% \end{split}
% \end{equation}
\end{array}
\right.
\]

% \noindent
Clasificación puede ser obtenida, por ejemplo, al medir la distancia Euclidiana de los vectores $({\alpha}_{0}, \dots ,{\alpha}_{d}, {\beta}_{0}, \dots ,{\beta}_{d})$ entre los distintos trazos.

Consideraremos \textbf{features} a estos vectores que tienen dimensión $2\:(d+1)$. En lo siguiente, se mostrará dos formas de calcularlos y, en secciones posteriores, resultados que avalen que los features son lo suficientemente representativos como para clasificar de manera precisa a los trazos.

% Se mostrará dos formas de calcularlos, una por medio de momentos matemáticos (sección \ref{HausdorffMomentProblem}) y otra a través aproximación por mínimo cuadrados usando la pseudo-inversa (sección \ref{leastSquare}), y resultados que avalen que los features son lo suficientemente representativos como para clasificar de manera precisa los trazos.




\subsection{Momentos}
\label{Momentos}

\subsubsection{Definición}
Los momentos matemáticos de una función $f$ definida en $[0,1]$ son
\begin{align}
\label{eq:momentos}
\mu_{k} & \doteq \int_{0}^{1}{f(\lambda)\,\lambda^k\,d\lambda}
\end{align}


\subsubsection{Hausdorff Moment Problem}
\label{HausdorffMomentProblem}
Este problema consiste en recuperar a partir de una secuencia finita de  momentos $\{\mu_k\}_{k=0,1,2,...}$ una función $f$ en el dominio $[0,1]$.
% Para un desarrollo más teórico del problema ver \cite{Moments}.
% Aquí se presenta una explicación simplificada.

Con el fin de facilitar el desarrollo, recordaremos algunas definiciones y ecuaciones previas.
%de la reconstrucción de funciones mediante momentos.
Se supondrá que el dominio es $[0,1]$, y que la función peso es $w(t)=1$ para poder trabajar con los polinomios de \textit{Legendre} (sección \ref{legendre}). Por lo que el producto interno en \refEQ{def:inner_product} queda
\begin{align}
\label{eq:inner_product_2}
 \langle f, g \rangle & = \int_{0}^{1}f(t)\,g(t)\,dt
\end{align}
Escribamos nuevamente la ecuación \refEQ{eq:legendre},
\begin{align*}
L_i(t) &= \sum_{j=0}^{i}{ C_{ij}\,x^j }
\end{align*}
y también la ecuación \refEQ{eq:aprox}, pero con el reemplazo de ${B}_{i}$ por ${L}_{i}$,
\begin{align*}
f(t) & \approx \sum_{i=0}^{d}{\alpha}_{i}\,{L}_{i}(t)
\end{align*}
Ahora, a partir de \vspace*{-0.4cm}
% \refEQ{eq:alpha_inner_prod}
% \begin{align*}
% {\alpha}_{i} & = \langle f, L_i \rangle
% \end{align*}
% & =  \quad \langle \rangle  \\
% & =  \quad \langle \rangle  \\
% & =  \quad \langle \rangle  \\
% & =  \quad \langle \rangle  \\
\begin{align*}
\hspace*{4cm}  & {\alpha}_{i}  \\
 = \quad &   \quad \langle \text{~ por}~\refEQ{eq:alpha_inner_prod} ~ \rangle  \\
   &   \langle f, L_i \rangle \\
 = \quad &   \quad \langle \text{~ expansión del producto interno}~\refEQ{eq:inner_product_2} ~ \rangle  \\
   &   \int_{0}^{1}f(t)\,L_i(t)\,dt \\
 = \quad &   \quad \langle \text{~ definición de $L_i(t)$, ecuación}~\refEQ{eq:legendre} ~ \rangle  \\
   &   \int_{0}^{1}f(t)\, \left( \sum_{j=0}^{i}{ C_{ij}\,x^j } \right) \,dt \\
 = \quad &   \quad \langle \text{~ reordenación de términos, sumatoria afuera} ~ \rangle  \\
   &   \sum_{j=0}^{i}{ C_{ij}\,\underbrace{\left( \int_{0}^{1}f(t)\,x^j\,dt \right)}_{\mu_j} } \\
 = \quad &   \quad \langle \text{~ definición de momento}~\refEQ{eq:momentos} ~ \rangle  \\
   &   \sum_{j=0}^{i}{ C_{ij}\,\mu_j}
\end{align*}


\noindent
Se puede escribir en forma matricial
\begin{align*}
% alpha vector
   \begin{bmatrix}
    \alpha_{0} \\
    \alpha_{1} \\
    \vdots \\
    \alpha_{d}
   \end{bmatrix}_{(d+1)}
& =
% C matrix
    \begin{bmatrix}
      C_{00} \\
      C_{10} & C_{11} \\
      \vdots & \vdots & \ddots \\
      C_{d0} & C_{d1} & \dots & C_{dd}
    \end{bmatrix}_{(d+1)\times(d+1)} \dot ~
% mu vector
\begin{bmatrix}
    \mu_{0} \\
    \mu_{1} \\
    \vdots \\
    \mu_{d}
   \end{bmatrix}_{(d+1)}
\end{align*}
Resumiendo,
\begin{align}
\label{eq:HMP}
   \mathbf{\alpha} & = \mathbf{C\,\mu}
\end{align}
donde $\mathbf{C}$ es la matriz de coeficientes de los polinomios de Legendre, y $\mathbf{\mu}$ un vector columna con los momentos matemáticos de la función a reconstruir. De esta manera, se tiene que el cálculo de~$\mathbf{\alpha}$, los coeficientes de la expansión finita por series de la función~$f$, se realiza a partir de una multiplicación matricial en la que intervienen los momentos.


\subsection{Cálculo numérico de los momentos}
Observar que en la ecuación anterior~\refEQ{eq:HMP}, la matriz~$\mathbf{C}$ puede ser precalcula con la fórmula~\refEQ{eq:legendre_coefficients}, o mediante el proceso de Gram-Schmidt~\refEQ{eq:Gram-Schmidt}. Cualquiera sea la forma en que se calcule los coeficientes de los polinomios de Legendre, es importante darse cuenta que solo es necesario realizarlo por única vez, por lo que es necesario focalizarse en el cálculo de los momentos.


\subsubsection{Momentos para funciones definidas en otros dominios}
Generalicemos la definición \refEQ{eq:momentos}, sea $f$ una función definida en $[0,\ell]$ los momentos de~$f$ son
\begin{align}
\label{eq:momentos_con_param}
\mu_{k}(f,\ell) \, & =\int_{0}^{\ell}{f(\lambda)\,\lambda^k\,d\lambda} \hspace*{13.5ex}
\end{align}
%  $[0,\ell]$
% sección \ref{legendre}

Al estar los polinomios de Legendre (shifted) definidos en $[0,1]$ es necesario calcular los momentos en ese dominio. Entonces, el problema aquí es cómo calcularlos a partir de una función~$f$ definida en $[0,\ell]$. Ésto se resuelve con un \textbf{cambio de variable} como se verá de inmediato.

Obsérvese que si se define,
\begin{align}
\gamma  & \doteq \frac{1}{\ell}\,\lambda  \quad \Longrightarrow \quad \lambda \in [0,\ell] \Leftrightarrow \gamma \in [0,1]  \hspace*{7ex}
\end{align}
entonces definamos,
\begin{align}
\label{eq:f_hat}
\hat{f}(\gamma) & \doteq f(\ell\,\gamma)  \hspace*{18ex} % = f(\lambda)
\end{align}

Ahora, partiendo de la definición \refEQ{eq:momentos_con_param},
\begin{align*}
\hspace*{4cm}  \mu_{k}(f,\ell) & = \int_{0}^{\ell}{f(\lambda)\,\lambda^k\,d\lambda}, \hspace*{7.9ex}
\begin{footnotesize}
\text{\textbf{cambio de variable}:}~
\left\{\hspace*{-1ex}
            \begin{array}{rl}
               \lambda  = & \hspace*{-2ex} \ell\,\gamma \\
               d\lambda = & \hspace*{-2ex} \ell\,d\gamma
            \end{array}
\right.
\end{footnotesize} \\
& = \int_{0}^{1}{f(\ell\,\gamma)\,(\ell\,\gamma)^k\,\ell\,d\gamma}, \hspace*{2.4ex}
\begin{footnotesize}\text{reordenando}\end{footnotesize} \\
& = \ell^{k+1}\int_{0}^{1}{f(\ell\,\gamma)\,\gamma^k\,d\gamma}, \quad
\begin{footnotesize}\text{por \refEQ{eq:f_hat}}\end{footnotesize} \\
& = \ell^{k+1}\underbrace{\int_{0}^{1}{\hat{f}(\gamma)\,\gamma^k\,d\gamma}}_{\mu_{k}(\hat{f},1)}, \hspace*{3.3ex}
\begin{footnotesize}\text{por \refEQ{eq:momentos_con_param}}\end{footnotesize} \\
& = \ell^{k+1}\,\mu_{k}(\hat{f},1)
\end{align*}
obtenemos,
\begin{align}
\label{eq:momentos_f_hat}
\mu_{k}(\hat{f},1)  & = \frac{\mu_{k}(f,\ell)}{\ell^{k+1}} \hspace*{19ex}
\end{align}


Por lo tanto, se utilizarán los momentos generalizados de la función~$f$ original en $[0,\ell]$ para calcular los momentos de la función~$\hat{f}$ en el dominio que se necesitan, es decir, $[0,1]$.



% \subsubsection{Cálculo numérico de los momentos}
% Se asume que muestras de $f$ irán recibiendo en tiempo real.
% que las funciones que se aproximan



% \subsection{Aproximación por mínimos cuadrados}
\label{leastSquare}

