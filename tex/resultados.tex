\section{Resultados}

En esta sección ... *** FALTA ***

\subsection{Bases de datos disponibles}

Se utilizó una base de datos disponible en \cite{LaViola}. Esta base de datos fue dividida en dos: base de datos de dígitos y de letras. La base de datos de dígito tiene~$1100$ muestras de~$11$ usuarios diferentes, que escribieron~$10$ veces cada número. Y la base de datos de letras contiene cerca de~$3600$ muestras. En la figura \ref{fig:db_digitos} se muestran~$10$ ejemplos normalizados a $[0,1]$ de la base de datos de dígitos.
    \begin{figure}[!htbp]
    \centering
    \vspace*{-0.6cm}
    \includegraphics[scale=0.65]{imagen/db_digitos.pdf}
    \vspace*{-0.6cm}
    \caption{Ejemplos de la dase de datos de dígitos}
    \label{fig:db_digitos}
    \end{figure}

En caso de que especifique lo contrario, las gráficas que se muestran a continuación corresponden a la base de datos de dígitos, suspendiendo el análisis de los resultados para la base de datos de letras hasta la sección \ref{sec:features_generales}.

\subsection{Validación}

La validación cruzada (o \textit{\textbf{cross-validation}}), es la práctica de partir una base de datos en subconjuntos de tal forma que el entrenamiento es realizado en algunos de ellos (\textit{\textbf{training}}), mientras los otros subconjuntos son retenidos para su uso posterior en la confirmación y validación del análisis inicial (\textit{\textbf{testing}}).

En \textit{\textbf{k-fold} cross-validation}, la base de datos es dividida en $k$ particiones. De las $k$ particiones, solo una se mantiene como datos de validación para testing, y las restante $k-1$ se utilizan para el entrenamiento. El proceso es repetido $k$ veces, de tal modo que cada una de las $k$ particiones es usada exactamente una vez para testing. Los $k$ resultados pueden ser promediados para producir una sola estimación. En este trabajo se ha utilizado 10-fold cross-validation.


\subsection{Entendiendo las gráficas}

A lo largo de esta sección se incluirán gráficas similares al estilo de la figura \ref{fig:graficas}.
    \begin{figure}[!htbp]
    \centering
%     \vspace*{-0.3cm}
    \includegraphics[scale=0.75]{imagen/plot/least_square_L_preproceso_1.pdf}
    \vspace*{-0.5cm}
    \caption{Ejemplos de gráfica.}
    \label{fig:graficas}
    \end{figure}


\subsection{Momentos vs Pseudo-inversa}
\subsection{Preprocesar o No Preprocesar}
\label{prepoceso}

Como se indicó en la sección \ref{sec:conceptos_preproceso}, antes del cálculo de los features se suelen usar~$3$ filtros como preproceso. Estos filtros son: 1. suavizado, 2. resampling, y 3. resizing (no necesariamente en ese orden). En lo siguiente se desea examinar la posibilidad de eliminar estos pasos en pos de eficiencia.

% El algoritmo de cálculo de momento puede ser implementado (como se vio en la sec) de manera tal que puedan ser calculados a medida que los datos se vayan introduciendo.

%Evitar utilizar estos filtros permitiría el cálculo de los momentos a medida que se van ingresando los datos, como se ha indicado en la sección \ref{sec:calculo_numerico_momentos}; lo cuál permitiría un aumento considerable de eficiencia en comparación con el método de la pseudo-inversa, el cual necesita esperar a que el usuario termine


\subsubsection{Evitando suavizado}
Recordar que los features son los coeficientes de polinomios, obtenidos por aproximación de mínimos cuadrados, lo cual genera una curva suave. El objetivo del suavizado (la eliminación del ruido presente al principio y final de cada trazo) es alcanzado sin necesidad de realizar un filtrado. Entonces, no es necesario este paso.

\subsubsection{Evitando resampling}
Al cambiar la representación de los trazos, de secuencia de puntos a curvas continuas, no hay necesidad de espaciarlos uniformemente o reducir/aumentar la cantidad de puntos en los trazos (tarea del filtro en cuestión). Si la velocidad en la que es escrito un símbolo afecta el reconocimiento, se puede optar por la reparametrización por longitud de arco, sección \ref{sec:arc-length}. Por lo tanto, tampoco es necesario el resampling.

\subsubsection{Evitando resizing}
Se ha demostrado que los features obtenidos son invariantes a escala, sección \ref{Invariante_escala}. Por lo que también es innecesario aplicar este filtro.

\subsubsection{Evitando traslación}
Un filtro no mencionado es aplicar traslación, que se ocupa de trasladar el trazo de manera tal que el mínimo de cada eje sea $0$. Se ha expresado que los features no son invariantes a traslación. Aquí se muestra por experimentación, que las traslaciones no provocan una pérdida significativa en la precisión de reconocimiento. Esto permitiría tomar dos caminos posibles al implementar un sistema de reconocimiento: preprocesar o no hacerlo. Observar que a pesar de que el preproceso se haya reducido a una simple traslación, el mínimo es conocido recién cuando el trazo es finalizado, no permitiendo así el cálculo de los momentos a medida que se escribe.

Esta decisión de diseño puede ser tomada para el caso en que se requiera extrema eficiencia, como el caso de los dispositivos móviles, evitando preprocesar a costa de perder precisión. Entonces, se tiene que evaluar en qué escenario se desea utilizar el sistema de reconocimiento, y elegir el balance justo entre eficiencia y precisión según sea el caso. Una comparación sobre la precisión de reconocimiento puede verse en~\ref{fig:prep_vs_no_prep}.
% \vspace*{-0.6cm}
\begin{figure}[!htbp]
  \centering
  \advance\leftskip-2.8cm
  \advance\rightskip-2.8cm
  \subfloat[Sin prepoceso]{\label{fig:prep}\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/moments_L_preproceso_0.pdf}}
  \subfloat[Con prepoceso]{\label{fig:no_prep}\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/moments_L_preproceso_1.pdf}}
  \caption{Momentos con polinomios de Legendre}
  \label{fig:prep_vs_no_prep}
\end{figure}


% \begin{figure}[h!]
%  \centering
%  \advance\leftskip-2.8cm
%  \advance\rightskip-2.8cm
%  \includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/moments_L_preproceso_0.pdf}
% \hspace*{-0.4cm}
% \includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/moments_L_preproceso_1.pdf}
%  \caption{Sin preproceso (izq.), y con preproceso (der.). Método: Momentos con polinomios de Legendre}
%  \label{fig:prep_vs_no_prep}
% \end{figure}



%  \includegraphics[scale=0.458,keepaspectratio=true]{imagen/plot/moments_L_preproceso_1.pdf}
%  \includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/moments_L_arc_preproceso_1.pdf}


\subsection{Parametrización por tiempo vs Parametrización por longitud de arco}
\subsection{Representación a elegir}
\subsubsection{Legendre, Chebyshev o Legendre-Sobolev}
\subsubsection{Elección del grado de los polinomios}

\subsection{Momentos como features}


\subsection{Features de propósitos general}
\label{sec:features_generales}
Observar que los features no fueron diseñados especialmente para símbolos particulares, en este caso los dígitos o las letras. Con la gráfica FFFF, se pretende mostrar que los features obtenidos no dependen del símbolo a ser reconocido, pues se aplicó el mismo algoritmo (sin modificaciones) a la base de datos de letras, y se consiguieron también buenos resultados. % (casi $96\%$ con los polinomios de grado $10$).
Entonces, los features se pueden considerar de propósitos general y pueden ser utilizados en diferentes situaciones, no sólo con los dígitos.


\subsection{Mejor performance}
\subsection{Mejor precisión}
