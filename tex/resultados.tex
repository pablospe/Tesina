\section{Resultados}

En esta sección se indicará sobre qué conjuntos de datos se ha trabajado y la forma de evaluación. También se compararán los diferentes métodos descripto a lo largo del presente trabajo.

\subsection{Base de datos}

La base de datos utilizada se encuentra disponible en \cite{LaViola}. Dicha base de datos fue subdividida en dos partes: base de datos de dígitos y base de datos de letras. La primera contiene~$1100$ muestras de~$11$ personas distintas que escribieron cada número~$10$ veces. Y la base de datos de letras contiene cerca de~$3600$ muestras. En la figura \ref{fig:db_digitos} se muestran~$10$ ejemplos normalizados a $[0,1]$ de la base de datos de dígitos.
    \begin{figure}[!htbp]
    \centering
    \vspace*{-0.6cm}
    \includegraphics[scale=0.65]{imagen/db_digitos.pdf}
    \vspace*{-0.6cm}
    \caption{Ejemplos de la dase de datos de dígitos}
    \label{fig:db_digitos}
    \end{figure}

En caso de que especifique lo contrario, las gráficas que se muestran a continuación corresponden a la base de datos de dígitos, suspendiendo el análisis de los resultados para la base de datos de letras hasta la sección \ref{sec:features_generales}.

\subsection{Validación}

La validación cruzada (o \textit{\textbf{cross-validation}}), es la práctica de partir una base de datos en subconjuntos de tal forma que el entrenamiento es realizado en algunos de ellos (\textit{\textbf{training}}), mientras los otros subconjuntos son retenidos para su uso posterior en la confirmación y validación del análisis inicial (\textit{\textbf{testing}}).

En \textit{\textbf{k-fold} cross-validation}, la base de datos es dividida en $k$ particiones. De las $k$ particiones, solo una se mantiene como datos de validación para testing, y las restante $k-1$ se utilizan para el entrenamiento. El proceso es repetido $k$ veces, de tal modo que cada una de las $k$ particiones es usada exactamente una vez para testing. Los $k$ resultados pueden ser promediados para producir una sola estimación. En este trabajo se ha utilizado 10-fold cross-validation.


\subsection{Entendiendo las gráficas}

A lo largo de esta sección se incluirán gráficas similares a la figura \ref{fig:graficas}.
    \begin{figure}[!htbp]
    \centering
%     \vspace*{-0.3cm}
    \includegraphics[scale=0.7]{imagen/plot/least_square_L_preproceso_1.pdf}
%     \vspace*{-0.5cm}
    \caption{Ejemplos de gráfica.}
    \label{fig:graficas}
    \end{figure}

En el título de las gráficas se indica la combinación de métodos y opciones usadas. A continuación se detallan los posibles valores:
\begin{itemize}
 \item  \textbf{Polinomio:} Legendre, Chebyshev o Legendre-Sobolev;
 \item  \textbf{Método:} Momentos o Mínimo Cuadrados (mediante pseudo-inversa, \textit{LeastSquare});
 \item  \textbf{Parametrización:} por tiempo o por longitud de arco (\textit{arc-length});
 \item  \textbf{Preproceso:} activado ($1$) o desactivado ($0$);
 \item  \textbf{libsvm:} los dos primeros parámetros son $C$ y $\gamma$, explicados en \ref{sec:grid}. Estos son pasado a la biblioteca \textit{libsvm}. Los demás parámetros son opciones internas de libsvm, que han elegido convenientemente y dejado fijas en todas las pruebas.
\end{itemize}

El eje $X$ de las gráficas representan el grado $d$ (\textit{degree}) de los polinomios elegidos, donde $d~\in~[3,20]$. Recordar que los \textit{features} son los vectores $({\alpha}_{0}, \dots ,{\alpha}_{d}, {\beta}_{0}, \dots ,{\beta}_{d})$ que tiene dimensión $2\,(d+1)$.

El eje $Y$ representa la \textit{\textbf{precisión}} alcanzada por el método, porcentaje de reconocimiento correcto, en el rango $[91,100]$.

Por último, la misma leyenda es utilizadas en todas las gráficas. Allí se indica el color de los métodos de \textit{clasificación} usados: $k$-NN, con alguna de sus distancias (Euclidiana, Cityblock o Mahalanobis), o LibSVM.


\subsection{Momentos vs Pseudo-inversa}

Se lo enumerarán algunas ventajas y desventajas del algoritmo de los momentos \ref{Momentos} frente a la pseudo-inversa~\ref{leastSquare}.

\begin{basedescript}{\desclabelwidth{2.3cm}}
\item[Ventajas:]
    \begin{itemize}
        \item El algoritmo se puede implementar de tal modo que los momentos se vayan calculando a medida que el usuario escriba el trazo, ver \ref{sec:calculo_numerico_momentos}. Por lo tanto, se puede dividir la complejidad computacional en: (1.) cálculos online (mientras se escribe), (2.) cálculos a partir de que se haya finalizado el trazo. Es necesario tomar solamente (2.) si se desea comparar con otro algoritmo que no tengan cálculos online, como el algoritmo de la pseudo-inversa. Se puede confirmar fácilmente que la parte (2.) del algoritmo de los momentos es \textbf{constante}. Esto sucede pues una vez calculados los momentos, solo se tiene que realizar una multiplicación matricial $\mathbf{\alpha}  = \mathbf{C\,\mu}$, para conseguir los features,
        \item Es mucho más sencillo de implementar que la pseudo-inversa.
    \end{itemize}

\item[Desventajas:]
    \begin{itemize}
    \item El algoritmo de los momentos solo funciona para los polinomios de Legendre. En cambio, con la pseudo-inversa se pueden utilizar polinomios ortogonales cualesquiera.
    \item El cálculo de momentos sufre de \textit{\textbf{inestabilidad numérica}} para~$d$ grandes. En la figura~\ref{fig:inestabilidad_numerica}, pueden verse aproximaciones para $\{d=9, d=12, \dots ,d=24\}$ de la función $u(t) = \mathrm{sin}\left( 3\,\pi \,t\right) -\frac{1}{2}\,\mathrm{sin}\left( \frac{15\,\pi \,t}{2}\right)$.
        \begin{figure}[!htbp]
            \centering
%             \vspace*{-0.3cm}
%             \advance\rightskip-1.5cm
            \includegraphics[scale=0.6]{imagen/inestabilidad_numerica.pdf}
%             \vspace*{-1cm}
            \caption{Momentos: inestabilidad numérica}
            \label{fig:inestabilidad_numerica}
        \end{figure}
    \end{itemize}

\end{basedescript}


No se enumerarán las ventajas y desventajas de la pseudo-inversa frente a los momentos, pues es la relación inversa. La ventaja de un método es la desventaja del otro.



\subsection{Preprocesar o No Preprocesar}
\label{prepoceso}

Como se indicó en la sección \ref{sec:conceptos_preproceso}, antes del cálculo de los features se suelen usar~$3$ filtros como preproceso. Estos filtros son: 1. suavizado, 2. resampling, y 3. resizing (no necesariamente en ese orden). En lo siguiente se desea examinar la posibilidad de eliminar estos pasos en pos de eficiencia.

% El algoritmo de cálculo de momento puede ser implementado (como se vio en la sec) de manera tal que puedan ser calculados a medida que los datos se vayan introduciendo.

%Evitar utilizar estos filtros permitiría el cálculo de los momentos a medida que se van ingresando los datos, como se ha indicado en la sección \ref{sec:calculo_numerico_momentos}; lo cuál permitiría un aumento considerable de eficiencia en comparación con el método de la pseudo-inversa, el cual necesita esperar a que el usuario termine


\subsubsection{Evitando suavizado}
Recordar que los features son los coeficientes de polinomios, obtenidos por aproximación de mínimos cuadrados, lo cual genera una curva suave. El objetivo del suavizado (la eliminación del ruido presente al principio y final de cada trazo) es alcanzado sin necesidad de realizar un filtrado. Entonces, no es necesario este paso.

\subsubsection{Evitando resampling}
Al cambiar la representación de los trazos, de secuencia de puntos a curvas continuas, no hay necesidad de espaciarlos uniformemente o reducir/aumentar la cantidad de puntos en los trazos (tarea del filtro en cuestión). Si la velocidad en la que es escrito un símbolo afecta el reconocimiento, se puede optar por la reparametrización por longitud de arco, sección \ref{sec:arc-length}. Por lo tanto, tampoco es necesario el resampling.

\subsubsection{Evitando resizing}
Se ha demostrado que los features obtenidos son invariantes a escala, sección \ref{Invariante_escala}. Por lo que también es innecesario aplicar este filtro.

\subsubsection{Evitando traslación}
Un filtro no mencionado es aplicar traslación, que se ocupa de trasladar el trazo de manera tal que el mínimo de cada eje sea $0$. Se ha expresado que los features no son invariantes a traslación. Aquí se muestra por experimentación, que las traslaciones no provocan una pérdida significativa en la precisión de reconocimiento. Esto permitiría tomar dos caminos posibles al implementar un sistema de reconocimiento: preprocesar o no hacerlo. Observar que a pesar de que el preproceso se haya reducido a una simple traslación, el mínimo de cada eje es conocido recién cuando el trazo es finalizado, lo cual implica que el preproceso no permite el cálculo de los momentos a medida que se escribe el trazo.

Esta decisión de diseño puede ser tomada para el caso en que se requiera extrema eficiencia, como el caso de los dispositivos móviles, evitando preprocesar a costa de perdida precisión. Entonces, se tiene que evaluar en qué escenario se desea utilizar el sistema de reconocimiento, y elegir el balance justo entre eficiencia y precisión según sea el caso. Una comparación puede verse en~\ref{fig:prep_vs_no_prep}, donde al no usar preproceso en \textbf{(a)} se tiene una pérdida de precisión del $2\%$ (considerando los mejores resultados) con respecto a~\textbf{(b)} que sí utiliza preproceso.
% \vspace*{-0.6cm}
\begin{figure}[!htbp]
  \centering
  \advance\leftskip-2.8cm
  \advance\rightskip-2.8cm
  \subfloat[Sin prepoceso]{\label{fig:prep}\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/moments_L_preproceso_0.pdf}}
  \subfloat[Con prepoceso]{\label{fig:no_prep}\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/moments_L_preproceso_1.pdf}}
  \caption{Momentos con polinomios de Legendre}
  \label{fig:prep_vs_no_prep}
\end{figure}

\subsection{Elección del grado $d$ de los polinomios}

Recordar llamamos $d$ al grado de los polinomios elegidos, y que los features tienen dimensión $2\,(d+1)$. Cabe señalar que a menor $d$, menos \textbf{cómputos}; pero no necesariamente a mayor $d$, más \textbf{precisión}. Se observa en las gráficas que generalmente se obtienen los máximos en el rango $[9,15]$. Por lo que una buena elección de $d$ podría ser: $9$, $12$ ó $15$. Este es un parámetro que debe elegirse a la hora de implementar un sistema de reconocimiento usando estas técnicas.

\subsection{Elección de la representación}
La mejor representación puede variar según el escenario. Como vimos con anterioridad, la mejor representación posible teniendo como prioridad la eficiencia se logra con el método de los momentos, polinomios de Legendre (preproceso desactivado), ver figura \ref{fig:prep}. Y la mejor representación posible en cuanto a precisión se obtuvo con los polinomios de Legendre-Sobolev (preproceso activo), ver figura~\ref{fig:mejor_rep_presicion}.
    \begin{figure}[!htbp]
    \centering
    \vspace*{-0.22cm}
    \includegraphics[scale=0.6]{imagen/plot/least_square_LS_preproceso_1.pdf}
    \vspace*{-0.42cm}
    \caption{Mejor representación considerando como prioridad la precisión.}
    \label{fig:mejor_rep_presicion}
    \end{figure}

También se ha probado con los polinomios de Chebyshev (ver gráfica \ref{fig:Legendre_vs_Chebyshev}), pero no se ha logrado mejoras significativas con respecto a Legendre. Motivamos por la falta de ventajas, y la desventaja de no poder utilizar momentos, se ha descartado esta representación.
 \vspace*{-0.6cm}
\begin{figure}[!htbp]
  \centering
  \advance\leftskip-2.8cm
  \advance\rightskip-2.8cm
  \subfloat[Legendre]{\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/least_square_L_preproceso_1.pdf}}
  \subfloat[Chebyshev]{\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/least_square_C_preproceso_1.pdf}}
  \caption{Legendre vs Chebyshev}
  \label{fig:Legendre_vs_Chebyshev}
\end{figure}

\subsection{Parametrización por tiempo vs Parametrización por longitud de arco}

Se ha indicado en \ref{sec:arc-length} que la parametrización por longitud de arco es usualmente preferible, pues no es afectada por variaciones en la velocidad de escritura. La pruebas realizadas no indican una mejora considerable, pero se sospecha que es por la calidad que posee la base de datos, la cual no parecería tener trazos con variaciones importantes en la velocidad de escritura.

% \begin{figure}[!htbp]
%   \centering
%   \advance\leftskip-2.8cm
%   \advance\rightskip-2.8cm
%   \subfloat[Parametrización por tiempo]{\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/least_square_L_preproceso_1.pdf}}
%   \subfloat[Parametrización por longitud de arco]{\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/least_square_L_arc_preproceso_1.pdf}}
% %   \subfloat[Parametrización por tiempo]{\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/least_square_LS_preproceso_1.pdf}}
% %   \subfloat[Parametrización por longitud de arco]{\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/least_square_LS_arc_preproceso_1.pdf}}  \\
% %   \subfloat[Parametrización por tiempo]{\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/moments_L_preproceso_1.pdf}}
% %   \subfloat[Parametrización por longitud de arco]{\includegraphics[scale=0.46,keepaspectratio=true]{imagen/plot/moments_L_arc_preproceso_1.pdf}}
%   \caption{Momentos con polinomios de Legendre}
%   \label{fig:asdf}
% \end{figure}


\subsection{Momentos como features}
En la ecuación \refEQ{eq:HMP},
\begin{align}
   \mathbf{\alpha} & = \mathbf{C\,\mu}
\end{align}
donde $C$ es la matriz de coeficientes de los polinomios de Legendre, puede verse que los únicos valores que cambian (de trazo en trazo) son los momentos~$\mu$, ya que $C$ está fija (precalculada). Por qué no intentar considerar entonces a los momentos como features. En la gráfica \ref{fig:momemts_as_features} el mejor método es k-NN con la distancia de Mahalanobis. Casi que no se ven las otras medidas, por el alto rango elegido de porcentaje de reconocimiento $[91,100]$. En estos resultados el preproceso estaba activado, pero si se desactiva el mejor método apenas supera el $90\%$ de precisión, con lo cuál no se puede utilizarlos sin preproceso.
    \begin{figure}[!htbp]
    \centering
    \vspace*{-0.2cm}
    \includegraphics[scale=0.6]{imagen/plot/moments_preproceso_1.pdf}
    \vspace*{-0.3cm}
    \caption{Momentos como features.}
    \label{fig:momemts_as_features}
    \end{figure}

Observar que la mejora en la eficiencia no es significativa, pues para calcular $\mathbf{\alpha}$ se requiere una única multiplicación matricial $\mathbf{C\,\mu}$. \textbf{Es mayor la pérdida de precisión que la ganancia en eficiencia}, por lo que no se recomienda su utilización, pero sí se remarca la simpleza del método.


\subsection{Features de propósitos general}
\label{sec:features_generales}
Observar que los features no fueron diseñados especialmente para símbolos particulares, como ser los dígitos o las letras. Con la gráfica \ref{fig:letras_LS}, se pretende mostrar que los features obtenidos no dependen del símbolo a ser reconocido, pues se aplicó el mismo algoritmo (sin modificaciones) a la base de datos de letras, y se consiguieron también buenos resultados. % (casi $96\%$ con los polinomios de grado $10$).
Entonces, los features se pueden considerar de propósitos general pudiendo ser utilizados en diferentes situaciones, y no sólo con los dígitos.

En la gráfica recién mencionada, se muestran los mejores resultados en cuanto a precisión, obtenidos con los polinomios de Legendre-Sobolev de grado $9$ con poco más de $96\,\%$ de reconocimiento correcto para la base de dato de letras.
%; y en cuanto a \textbf{eficiencia}, obtenidos con momentos sin preprocesar los datos alcanzando un máximo de $9??\,\%$. Este último es el método más eficiente por las consideraciones hechas en el apartado \ref{prepoceso}.
    \begin{figure}[!htbp]
    \centering
    \vspace*{-0.2cm}
    \includegraphics[scale=0.6]{imagen/plot/least_square_LS_letras_preproceso_1.pdf}
    \vspace*{-0.2cm}
    \caption{Mejores resultados para la base de dato de letras.}
    \label{fig:letras_LS}
    \end{figure}
